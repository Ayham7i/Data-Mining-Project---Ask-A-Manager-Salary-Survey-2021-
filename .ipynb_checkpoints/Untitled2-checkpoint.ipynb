{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75874c9b-b5fb-4718-974a-0da2982be52a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'your_dataset_here' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 97\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# ======================================================\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# Example Usage\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# ======================================================\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;66;03m# Load and preprocess data (replace with your actual dataset)\u001b[39;00m\n\u001b[1;32m---> 97\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([\u001b[43myour_dataset_here\u001b[49m])  \u001b[38;5;66;03m# Use the provided dataset\u001b[39;00m\n\u001b[0;32m     98\u001b[0m     df, features, target \u001b[38;5;241m=\u001b[39m preprocess_data(df)\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;66;03m# Split data (train/test)\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'your_dataset_here' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "# ======================================================\n",
    "# Data Preprocessing\n",
    "# ======================================================\n",
    "def preprocess_data(df):\n",
    "    # Filter to USD and USA for consistency\n",
    "    df = df[(df['currency'] == 'usd') & (df['country'] == 'usa')]\n",
    "    \n",
    "    # Convert salary to categories\n",
    "    def salary_category(salary):\n",
    "        if salary < 50000:\n",
    "            return 'Low'\n",
    "        elif 50000 <= salary <= 100000:\n",
    "            return 'Medium'\n",
    "        else:\n",
    "            return 'High'\n",
    "    df['salary_category'] = df['annual salary'].apply(salary_category)\n",
    "    \n",
    "    # Select relevant features\n",
    "    features = [\n",
    "        'how old are you?',\n",
    "        'industry',\n",
    "        'overall years of professional experience',\n",
    "        'highest level of education completed',\n",
    "        'gender'\n",
    "    ]\n",
    "    target = 'salary_category'\n",
    "    \n",
    "    # Drop rows with missing values\n",
    "    df = df[features + [target]].dropna()\n",
    "    return df, features, target\n",
    "\n",
    "# ======================================================\n",
    "# ID3 Algorithm Implementation\n",
    "# ======================================================\n",
    "class DecisionNode:\n",
    "    def __init__(self, feature=None, branches=None, label=None):\n",
    "        self.feature = feature    # Feature to split on\n",
    "        self.branches = branches  # Dict: {feature_value: child_node}\n",
    "        self.label = label        # Leaf node label (salary category)\n",
    "\n",
    "def entropy(labels):\n",
    "    counts = Counter(labels)\n",
    "    total = len(labels)\n",
    "    return -sum((count / total) * math.log2(count / total) for count in counts.values())\n",
    "\n",
    "def information_gain(data, feature, target):\n",
    "    total_entropy = entropy(data[target])\n",
    "    values = data[feature].unique()\n",
    "    weighted_entropy = 0\n",
    "    \n",
    "    for value in values:\n",
    "        subset = data[data[feature] == value]\n",
    "        subset_entropy = entropy(subset[target])\n",
    "        weighted_entropy += (len(subset) / len(data)) * subset_entropy\n",
    "    \n",
    "    return total_entropy - weighted_entropy\n",
    "\n",
    "def id3(data, features, target):\n",
    "    # Base cases\n",
    "    labels = data[target]\n",
    "    if len(set(labels)) == 1:\n",
    "        return DecisionNode(label=labels.iloc[0])\n",
    "    if not features:\n",
    "        majority_label = Counter(labels).most_common(1)[0][0]\n",
    "        return DecisionNode(label=majority_label)\n",
    "    \n",
    "    # Select best feature (max information gain)\n",
    "    gains = {feature: information_gain(data, feature, target) for feature in features}\n",
    "    best_feature = max(gains, key=gains.get)\n",
    "    \n",
    "    # Recursively build the tree\n",
    "    branches = {}\n",
    "    for value in data[best_feature].unique():\n",
    "        subset = data[data[best_feature] == value]\n",
    "        remaining_features = [f for f in features if f != best_feature]\n",
    "        branches[value] = id3(subset, remaining_features, target)\n",
    "    \n",
    "    return DecisionNode(feature=best_feature, branches=branches)\n",
    "\n",
    "def predict(tree, sample):\n",
    "    if tree.label is not None:\n",
    "        return tree.label\n",
    "    feature_value = sample[tree.feature]\n",
    "    if feature_value not in tree.branches:\n",
    "        return Counter(tree.branches.values()).most_common(1)[0][0].label\n",
    "    return predict(tree.branches[feature_value], sample)\n",
    "\n",
    "# ======================================================\n",
    "# Example Usage\n",
    "# ======================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess data (replace with your actual dataset)\n",
    "    df = pd.DataFrame([your_dataset_here])  # Use the provided dataset\n",
    "    df, features, target = preprocess_data(df)\n",
    "    \n",
    "    # Split data (train/test)\n",
    "    train = df.sample(frac=0.8, random_state=42)\n",
    "    test = df.drop(train.index)\n",
    "    \n",
    "    # Build the tree\n",
    "    tree = id3(train, features, target)\n",
    "    \n",
    "    # Evaluate accuracy\n",
    "    correct = 0\n",
    "    for _, row in test.iterrows():\n",
    "        prediction = predict(tree, row)\n",
    "        if prediction == row[target]:\n",
    "            correct += 1\n",
    "    print(f\"Accuracy: {correct / len(test):.2f}\")\n",
    "\n",
    "    # Example prediction\n",
    "    sample = {\n",
    "        'how old are you?': '25-34',\n",
    "        'industry': 'computing or tech',\n",
    "        'overall years of professional experience': '5-7 years',\n",
    "        'highest level of education completed': 'master\\'s degree',\n",
    "        'gender': 'woman'\n",
    "    }\n",
    "    print(f\"Predicted Salary Category: {predict(tree, sample)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8340c4-2883-4f36-9015-6ca4139f7b2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
